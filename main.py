import os
import io
import time
import tempfile
import requests
import streamlit as st
from typing import Optional, Tuple, List

# Audio/Video
from moviepy.editor import VideoFileClip  # requires ffmpeg installed
from faster_whisper import WhisperModel   # local transcription

# ---------- Config ----------
LMSTUDIO_API_URL = "http://localhost:1234/v1/chat/completions"
DEFAULT_MODEL = "gemma-3-12b-it"  # LM Studio model id
DEFAULT_LANGUAGE = "ru"           # force language for whisper
WHISPER_MODEL_SIZE = "large-v3"   # faster-whisper local model

st.set_page_config(page_title="üéôÔ∏è–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞—Ç—å –∞—É–¥–∏–æ", page_icon="üóíÔ∏è", layout="wide")

# ---------- Utils ----------

def save_uploaded_file(uploaded_file) -> str:
    """Persist uploaded file to a temp path and return its path."""
    suffix = os.path.splitext(uploaded_file.name)[1].lower()
    tmp = tempfile.NamedTemporaryFile(delete=False, suffix=suffix)
    tmp.write(uploaded_file.read())
    tmp.flush()
    tmp.close()
    return tmp.name

def extract_audio_from_video(video_path: str) -> str:
    """Extract audio (wav) from a video using moviepy/ffmpeg."""
    out_wav = tempfile.NamedTemporaryFile(delete=False, suffix=".wav").name
    clip = VideoFileClip(video_path)
    try:
        clip.audio.write_audiofile(out_wav, verbose=False, logger=None)
    finally:
        clip.close()
    return out_wav

def transcribe_audio_whisper(audio_path: str,
                             language: str = "ru",
                             beam_size: int = 5,
                             vad_filter: bool = True,
                             device: Optional[str] = None) -> Tuple[str, List[Tuple[float, float, str]]]:
    """
    Transcribe using faster-whisper.
    Returns full text and segments list of (start, end, text).
    """
    # device: None -> auto; options: "cuda", "cpu"
    model = WhisperModel(WHISPER_MODEL_SIZE, device=device or "auto", compute_type="auto")
    segments_iter, info = model.transcribe(
        audio_path,
        language=language,
        beam_size=beam_size,
        vad_filter=vad_filter,
        vad_parameters=dict(min_silence_duration_ms=300)
    )
    segments = []
    full_text_chunks = []
    for seg in segments_iter:
        segments.append((seg.start, seg.end, seg.text))
        full_text_chunks.append(seg.text.strip())
    full_text = "\n".join([t for t in full_text_chunks if t])
    return full_text.strip(), segments

def call_lmstudio_chat(
    system_prompt: str,
    user_prompt: str,
    model: str = DEFAULT_MODEL,
    temperature: float = 0.7,
    max_tokens: int = 1200,
    timeout: float = 60.0
) -> str:
    """
    Call LM Studio‚Äôs OpenAI-compatible chat endpoint.
    """
    payload = {
        "model": model,
        "temperature": temperature,
        "max_tokens": max_tokens,
        "messages": [
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ]
    }
    resp = requests.post(LMSTUDIO_API_URL, json=payload, timeout=timeout)
    resp.raise_for_status()
    data = resp.json()
    try:
        return data["choices"][0]["message"]["content"]
    except Exception:
        return str(data)

def make_protocol_prompt() -> str:
    return (
        "–°–æ–∑–¥–∞–π —Ç–µ–∫—Å—Ç –≤ —Å—Ç–∏–ª–µ –ø—Ä–æ—Ç–æ–∫–æ–ª—å–Ω—ã—Ö —Ä–µ—à–µ–Ω–∏–π, —Ä–∞–∑–¥–µ–ª–∏–≤ –µ–≥–æ –ø–æ —Ä–æ–ª—è–º –≥–æ–≤–æ—Ä—è—â–∏—Ö. "
        "–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä—É–π –∫–∞–∫ –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω—ã–π –ø—Ä–æ—Ç–æ–∫–æ–ª —Å–æ–±—Ä–∞–Ω–∏—è: —É–∫–∞–∂–∏ –¥–∞—Ç—É (–µ—Å–ª–∏ –≤ —Ç–µ–∫—Å—Ç–µ –µ—Å—Ç—å), "
        "—Å–ø–∏—Å–æ–∫ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ (–ø–æ —Ä–µ–ø–ª–∏–∫–∞–º, –µ—Å–ª–∏ —è–≤–Ω–æ –Ω–µ —É–∫–∞–∑–∞–Ω—ã ‚Äî –ø—Ä–µ–¥–ª–æ–∂–∏ —Ä–æ–ª–∏), –ø–æ–≤–µ—Å—Ç–∫—É (–µ—Å–ª–∏ –≤—ã–≤–æ–¥–∏–º–∞), "
        "–∏ –ø–æ –∫–∞–∂–¥–æ–º—É –≤–æ–ø—Ä–æ—Å—É ‚Äî –∫—Ä–∞—Ç–∫–∏–µ –∑–∞–ø–∏—Å–∏, —Ä–µ—à–µ–Ω–∏—è, –ø–æ—Ä—É—á–µ–Ω–∏—è –∏ —Å—Ä–æ–∫–∏. "
        "–û—Ñ–æ—Ä–º–∏ —Ä–∞–∑–¥–µ–ª—ã: ¬´–£—á–∞—Å—Ç–Ω–∏–∫–∏¬ª, ¬´–ü–æ–≤–µ—Å—Ç–∫–∞¬ª, ¬´–•–æ–¥ –∑–∞—Å–µ–¥–∞–Ω–∏—è¬ª, ¬´–ü—Ä–∏–Ω—è—Ç—ã–µ —Ä–µ—à–µ–Ω–∏—è¬ª, ¬´–ü–æ—Ä—É—á–µ–Ω–∏—è¬ª. "
        "–ù–µ –¥–æ–±–∞–≤–ª—è–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏ –æ—Ç —Å–µ–±—è, –Ω–µ –ø–µ—Ä–µ—Å–∫–∞–∑, –∞ —á—ë—Ç–∫–∏–π –ø—Ä–æ—Ç–æ–∫–æ–ª."
    )

def format_segments_table(segments: List[Tuple[float, float, str]]) -> str:
    lines = ["–ù–∞—á–∞–ª–æ\t–ö–æ–Ω–µ—Ü\t–¢–µ–∫—Å—Ç"]
    for s, e, t in segments:
        lines.append(f"{s:.2f}\t{e:.2f}\t{t.strip()}")
    return "\n".join(lines)

def download_button_bytes(text: str, filename: str, label: str):
    return st.download_button(
        label=label,
        data=text.encode("utf-8"),
        file_name=filename,
        mime="text/plain"
    )

# ---------- UI ----------

st.title("üéôÔ∏è–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä–æ–≤–∞—Ç—å –∞—É–¥–∏–æ")

with st.sidebar:
    st.header("‚öôÔ∏è –ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    language = st.selectbox("–Ø–∑—ã–∫ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è (Whisper)", ["ru", "en", "auto"], index=0)
    temperature = st.slider("Temperature (LM)", 0.0, 1.5, 0.7, 0.1)
    max_tokens = st.slider("Max tokens (LM)", 128, 16000, 12000, 64)
    beam_size = st.slider("Beam size (Whisper)", 1, 10, 5, 1)
    vad_filter = st.checkbox("VAD —Ñ–∏–ª—å—Ç—Ä (—Ç–∏—à–∏–Ω–∞)", value=True)
    device_choice = st.selectbox("–£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ", ["auto", "cuda", "cpu"], index=0)
    model_name = st.text_input("LM Studio model", value=DEFAULT_MODEL)
    st.markdown("---")
    st.markdown("**–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:** ffmpeg, `faster-whisper`, `moviepy`, `streamlit`. LM Studio ‚Äî –∑–∞–ø—É—â–µ–Ω —Å REST API.")

# üëá –¥–æ–±–∞–≤–∏–ª –ø–æ–¥–¥–µ—Ä–∂–∫—É .m4a
uploaded = st.file_uploader(
    "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∞—É–¥–∏–æ/–≤–∏–¥–µ–æ (.mp3, .mp4, .m4a)",
    type=["mp3", "mp4", "m4a"]
)

go = st.button("–ó–∞–ø—É—Å—Ç–∏—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É üöÄ", type="primary", disabled=uploaded is None)

if uploaded and go:
    try:
        with st.status("–ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ñ–∞–π–ª–æ–≤‚Ä¶", expanded=False) as status:
            src_path = save_uploaded_file(uploaded)
            ext = os.path.splitext(src_path)[1].lower()
            status.update(label="–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞‚Ä¶")

            # –≤–∏–¥–µ–æ ‚Äî —Ç–æ–ª—å–∫–æ .mp4 (m4a —Å—á–∏—Ç–∞–µ–º –∞—É–¥–∏–æ)
            is_video = ext == ".mp4"

            if is_video:
                status.update(label="–ò–∑–≤–ª–µ–∫–∞—é –∞—É–¥–∏–æ –∏–∑ –≤–∏–¥–µ–æ‚Ä¶")
                audio_path = extract_audio_from_video(src_path)
            else:
                # mp3 –∏ m4a –∏–¥—É—Ç –Ω–∞–ø—Ä—è–º—É—é –≤ whisper
                audio_path = src_path

            status.update(label="–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É—é...")
            with st.spinner("Whisper —Ä–∞–±–æ—Ç–∞–µ—Ç‚Ä¶ —ç—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è ‚è≥"):
                transcript, segments = transcribe_audio_whisper(
                    audio_path=audio_path,
                    language=None if language == "auto" else language,
                    beam_size=beam_size,
                    vad_filter=vad_filter,
                    device=None if device_choice == "auto" else device_choice
                )

            if not transcript.strip():
                st.error("–ù–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –∫–∞—á–µ—Å—Ç–≤–æ –∞—É–¥–∏–æ/—è–∑—ã–∫.")
                status.update(label="–û—à–∏–±–∫–∞ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏", state="error")
            else:
                status.update(label="–§–æ—Ä–º–∞—Ç–∏—Ä—É—é –≤ –ø—Ä–æ—Ç–æ–∫–æ–ª‚Ä¶")
                system_msg = "–¢—ã –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π —Å–µ–∫—Ä–µ—Ç–∞—Ä—å –∑–∞—Å–µ–¥–∞–Ω–∏–π. –ü–∏—à–∏ –∫—Ä–∞—Ç–∫–æ, –æ—Ñ–∏—Ü–∏–∞–ª—å–Ω–æ, —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–æ."
                user_msg = f"{make_protocol_prompt()}\n\n–ù–∏–∂–µ ‚Äî —Ä–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞ —Å—Ç–µ–Ω–æ–≥—Ä–∞–º–º—ã:\n\n{transcript}"

                with st.spinner("–§–æ—Ä–º–∞—Ç–∏—Ä—É—é —Ç–µ–∫—Å—Ç‚Ä¶"):
                    protocol_text = call_lmstudio_chat(
                        system_prompt=system_msg,
                        user_prompt=user_msg,
                        model=model_name,
                        temperature=temperature,
                        max_tokens=max_tokens
                    )

                status.update(label="–ì–æ—Ç–æ–≤–æ ‚úÖ", state="complete")

        col1, col2 = st.columns(2)
        with col1:
            st.subheader("üìù –†–∞—Å—à–∏—Ñ—Ä–æ–≤–∫–∞")
            st.text_area("Transcript", transcript, height=360)
            download_button_bytes(transcript, "transcript.txt", "–°–∫–∞—á–∞—Ç—å transcript.txt")

            with st.expander("–°–µ–≥–º–µ–Ω—Ç—ã (–≤—Ä–µ–º—è –Ω–∞—á–∞–ª–∞/–∫–æ–Ω—Ü–∞)"):
                st.text(format_segments_table(segments))

        with col2:
            st.subheader("üìë –ü—Ä–æ—Ç–æ–∫–æ–ª")
            st.text_area("Protocol", protocol_text, height=360)
            download_button_bytes(protocol_text, "protocol.txt", "–°–∫–∞—á–∞—Ç—å protocol.txt")

        st.success("–ü–∞–∫–µ—Ç –¥–æ—Å—Ç–∞–≤–ª–µ–Ω. –ï—Å–ª–∏ –Ω—É–∂–Ω–æ ‚Äî –¥–æ–±–∞–≤–∏–º –≤—ã–≥—Ä—É–∑–∫—É –≤ DOCX/Markdown/JSON.")
    except requests.exceptions.ConnectionError:
        st.error("–ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ LM Studio API. –£–±–µ–¥–∏—Å—å, —á—Ç–æ LM Studio –∑–∞–ø—É—â–µ–Ω –∏ REST API –≤–∫–ª—é—á—ë–Ω (http://localhost:1234).")
    except Exception as e:
        st.exception(e)
